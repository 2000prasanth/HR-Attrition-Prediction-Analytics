# -*- coding: utf-8 -*-
"""To pickle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15UA3f-WiZIgllN8D85FZ74jVeoi08k8w
"""

import pandas as pd
import numpy as np
import pickle as pkl
data = pd.read_excel(r'C:\Users\USER\Desktop\DSA course\HR AV hacakthon\Employee-attrition.xlsx')

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

data['Attrition'] = le.fit_transform(data['Attrition'])

data = data.drop('Age', axis=1)

data = data.drop('Over18', axis=1)


data['BusinessTravel']=le.fit_transform(data['BusinessTravel'])

data['Department']=le.fit_transform(data['Department'])

data['Gender']=le.fit_transform(data['Gender'])

data['MaritalStatus']=le.fit_transform(data['MaritalStatus'])

mapping = {'Life Sciences': 1, 'Other': 2, 'Medical': 3, 'Marketing': 4, 'Technical Degree': 5, 'Human Resources': 6}
# Apply the mapping to the column
data['EducationField'] = data['EducationField'].map(mapping)

mapping1 = {
    'Healthcare Representative': 1,
    'Research Scientist': 2,
    'Sales Executive': 3,
    'Human Resources': 4,
    'Research Director': 5,
    'Laboratory Technician': 6,
    'Manufacturing Director': 7,
    'Sales Representative': 8,
    'Manager': 9
}
# Apply the mapping to the column
data['JobRole'] = data['JobRole'].map(mapping1)
# Handle missing values using imputation

''''
Business travel: 2=Rarely ,1=Frequently ,0=No travel

Department: 2=Sales, 1=R&D, 0=HR

Job Role: Life Sciences': 1, 'Other': 2, 'Medical': 3, 'Marketing': 4, 'Technical Degree': 5, 'Human Resources': 6

Martial status: 1=Married ,2=Single,3=Divorced

Attrition: 0=No, 1=Yes

Education Field Life: 'Healthcare Representative': 1, 'Research Scientist': 2, 'Sales Executive': 3, 'Human Resources': 4, 'Research Director': 5, 'Laboratory Technician': 6, 'Manufacturing Director': 7, 'Sales Representative': 8, 'Manager': 9

'''
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Select features and target
X = data.drop('Attrition', axis=1)  # Features
y = data['Attrition']  # Target
X=X.drop('Unnamed: 0', axis=1)
from sklearn.model_selection import train_test_split
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#random_forest = RandomForestClassifier(random_state=21)#
#random_forest=RandomForestClassifier(criterion='entropy', max_depth=120, n_estimators=1400)
best_random_params = {
    'bootstrap': True,
    'ccp_alpha': 0.0,
    'class_weight': None,
    'criterion': 'entropy',
    'max_depth': 120,
    'max_features': 'sqrt',
    'max_leaf_nodes': None,
    'max_samples': None,
    'min_impurity_decrease': 0.0,
    'min_samples_leaf': 1,
    'min_samples_split': 2,
    'min_weight_fraction_leaf': 0.0,
    'n_estimators': 1400,
    'n_jobs': None,
    'oob_score': False,
    'random_state': None,
    'verbose': 0,
    'warm_start': False
}
best_random_forest = RandomForestClassifier(**best_random_params)
# Fit the model with your training data
best_random_forest.fit(X_train, y_train)
y_pred_best = best_random_forest.predict(X_test)

# Evaluate the model's performance
accuracy_best = accuracy_score(y_test, y_pred_best)
print("Accuracy with best parameters:", accuracy_best)

with open('best_random_forest_model1.pkl', 'wb') as model_file:
    pkl.dump(best_random_forest, model_file)
